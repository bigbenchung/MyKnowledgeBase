{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "72db5965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from local file system:\n",
    "fruits = sc.textFile('data/fruits.txt')\n",
    "yellowThings = sc.textFile('data/yellowthings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "46d3d390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'canary melon', 'grap', 'lemon', 'orange', 'pineapple', 'strawberry']\n",
      "['banana', 'bee', 'butter', 'canary melon', 'gold', 'lemon', 'pineapple', 'sunflower']\n"
     ]
    }
   ],
   "source": [
    "# Convert RDD to list\n",
    "print(fruits.collect())\n",
    "print(yellowThings.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a38ec494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Get number of partitions\n",
    "print(fruits.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4d1653dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apple', 'banana', 'canary melon', 'grap', 'lemon'], ['orange', 'pineapple', 'strawberry']]\n",
      "[['banana', 'bee', 'butter', 'canary melon', 'gold'], ['lemon', 'pineapple', 'sunflower']]\n"
     ]
    }
   ],
   "source": [
    "# Get each partition\n",
    "print(fruits.glom().collect())\n",
    "print(yellowThings.glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb109457",
   "metadata": {},
   "source": [
    "----------\n",
    "\n",
    "##  RDD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fe09dfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elppa', 'ananab', 'nolem yranac', 'parg', 'nomel', 'egnaro', 'elppaenip', 'yrrebwarts']\n"
     ]
    }
   ],
   "source": [
    "# Reverse string for each element\n",
    "fruitsReversed = fruits.map(lambda fruit: fruit[::-1])\n",
    "print(fruitsReversed.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d2198871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'grap', 'lemon']\n"
     ]
    }
   ],
   "source": [
    "# filter\n",
    "shortFruits = fruits.filter(lambda fruit: len(fruit) <= 5)\n",
    "print(shortFruits.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fadde0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'p', 'p', 'l', 'e', 'b', 'a', 'n', 'a', 'n', 'a', 'c', 'a', 'n', 'a', 'r', 'y', ' ', 'm', 'e', 'l', 'o', 'n', 'g', 'r', 'a', 'p', 'l', 'e', 'm', 'o', 'n', 'o', 'r', 'a', 'n', 'g', 'e', 'p', 'i', 'n', 'e', 'a', 'p', 'p', 'l', 'e', 's', 't', 'r', 'a', 'w', 'b', 'e', 'r', 'r', 'y']\n"
     ]
    }
   ],
   "source": [
    "# flatMap\n",
    "characters = fruits.flatMap(lambda fruit: fruit)\n",
    "print(characters.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6a56137b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'canary melon', 'grap', 'lemon', 'orange', 'pineapple', 'strawberry', 'banana', 'bee', 'butter', 'canary melon', 'gold', 'lemon', 'pineapple', 'sunflower']\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# union\n",
    "fruitsAndYellowThings = fruits.union(yellowThings)\n",
    "print(fruitsAndYellowThings.collect())\n",
    "print(fruitsAndYellowThings.getNumPartitions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1d464eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pineapple', 'canary melon', 'lemon', 'banana']\n"
     ]
    }
   ],
   "source": [
    "# intersection\n",
    "yellowFruits = fruits.intersection(yellowThings)\n",
    "print(yellowFruits.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0728253f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orange', 'apple', 'grap', 'strawberry']\n"
     ]
    }
   ],
   "source": [
    "# subtraction\n",
    "subtracted_fruit = fruits.subtract(yellowThings)\n",
    "print(subtracted_fruit.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8015adb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orange', 'pineapple', 'canary melon', 'lemon', 'bee', 'banana', 'butter', 'gold', 'sunflower', 'apple', 'grap', 'strawberry']\n"
     ]
    }
   ],
   "source": [
    "# distinct\n",
    "distinctFruitsAndYellowThings = fruitsAndYellowThings.distinct()\n",
    "print(distinctFruitsAndYellowThings.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e408bf1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apple', 'banana'), ('apple', 'bee'), ('apple', 'butter'), ('apple', 'canary melon'), ('apple', 'gold'), ('banana', 'banana'), ('banana', 'bee'), ('banana', 'butter'), ('banana', 'canary melon'), ('banana', 'gold'), ('canary melon', 'banana'), ('canary melon', 'bee'), ('canary melon', 'butter'), ('canary melon', 'canary melon'), ('canary melon', 'gold'), ('grap', 'banana'), ('grap', 'bee'), ('grap', 'butter'), ('grap', 'canary melon'), ('grap', 'gold'), ('lemon', 'banana'), ('lemon', 'bee'), ('lemon', 'butter'), ('lemon', 'canary melon'), ('lemon', 'gold'), ('apple', 'lemon'), ('apple', 'pineapple'), ('apple', 'sunflower'), ('banana', 'lemon'), ('banana', 'pineapple'), ('banana', 'sunflower'), ('canary melon', 'lemon'), ('canary melon', 'pineapple'), ('canary melon', 'sunflower'), ('grap', 'lemon'), ('grap', 'pineapple'), ('grap', 'sunflower'), ('lemon', 'lemon'), ('lemon', 'pineapple'), ('lemon', 'sunflower'), ('orange', 'banana'), ('orange', 'bee'), ('orange', 'butter'), ('orange', 'canary melon'), ('orange', 'gold'), ('pineapple', 'banana'), ('pineapple', 'bee'), ('pineapple', 'butter'), ('pineapple', 'canary melon'), ('pineapple', 'gold'), ('strawberry', 'banana'), ('strawberry', 'bee'), ('strawberry', 'butter'), ('strawberry', 'canary melon'), ('strawberry', 'gold'), ('orange', 'lemon'), ('orange', 'pineapple'), ('orange', 'sunflower'), ('pineapple', 'lemon'), ('pineapple', 'pineapple'), ('pineapple', 'sunflower'), ('strawberry', 'lemon'), ('strawberry', 'pineapple'), ('strawberry', 'sunflower')]\n"
     ]
    }
   ],
   "source": [
    "# Cartesian product\n",
    "cartesian_fruits = fruits.cartesian(yellowThings) \n",
    "print(cartesian_fruits.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2c85409c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('apple', 'banana'), ('banana', 'bee'), ('canary melon', 'butter'), ('grap', 'canary melon'), ('lemon', 'gold'), ('orange', 'lemon'), ('pineapple', 'pineapple'), ('strawberry', 'sunflower')]\n",
      "[('apple', 0), ('banana', 1), ('canary melon', 2), ('grap', 3), ('lemon', 4), ('orange', 5), ('pineapple', 6), ('strawberry', 7)]\n",
      "[[('apple', 0), ('banana', 2), ('canary melon', 4), ('grap', 6), ('lemon', 8)], [('orange', 1), ('pineapple', 3), ('strawberry', 5)]]\n"
     ]
    }
   ],
   "source": [
    "# zip \n",
    "print(fruits.zip(yellowThings).collect())\n",
    "\n",
    "#Can only zip with RDD which has the same number of partitions\n",
    "#print(fruits.zip(newyellowThings).collect())\n",
    "\n",
    "print(fruits.zipWithIndex().collect())\n",
    "\n",
    "# Items in the kth partition will get ids k, n+k, 2*n+k, â€¦, where n is the number of partitions. \n",
    "# This is more efficient since each partition is processed independently\n",
    "print(fruits.zipWithUniqueId().glom().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e0e794",
   "metadata": {},
   "source": [
    "### RDD actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2b3e0fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# count\n",
    "numFruits = fruits.count()\n",
    "print(numFruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ff2a5137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'canary melon']\n"
     ]
    }
   ],
   "source": [
    "# take\n",
    "first3Fruits = fruits.take(3)\n",
    "print(first3Fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9e076a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Tip: Don't use count() when you don't need to return the exact number of rows\n",
    "# use take() or isEmpty()\n",
    "print(fruits.isEmpty())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3e97773b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "print(fruits.map(lambda fruit: len(fruit)).sum())\n",
    "print(fruits.map(lambda fruit: len(fruit)).reduce(lambda x, y: x+y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "57605779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2, 1], [3, 4], [5, 2]]\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "# the reduce function must be associative; otherwise the result is nondeterministic and depends on the partitioning\n",
    "rdd = sc.parallelize([1, 2, 1, 3, 4, 5, 2], 4)\n",
    "print(rdd.glom().collect())\n",
    "print(rdd.reduce(lambda x, y: 2*x+y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "edb15124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o', 'r', 'a', 'i', 'p', 'g', 'c', ' ', 'l', 'y', 'e', 'w', 'n', 'b', 'm', 't', 's'}\n"
     ]
    }
   ],
   "source": [
    "# reduce\n",
    "letterSet = fruits.map(lambda fruit: set(fruit)).reduce(lambda x, y: x.union(y))\n",
    "print(letterSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "57c25c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o', 'r', 'a', 'i', 'p', 'g', 'c', ' ', 'l', 'y', 'e', 'w', 'n', 'b', 'm', 't', 's'}\n"
     ]
    }
   ],
   "source": [
    "# treeReduce \n",
    "# Data are combined partially on a small set of executors before they are sent to the driver, \n",
    "# which dramatically reduces the load the driver has to deal with. \n",
    "\n",
    "letterSet = fruits.map(lambda fruit: set(fruit)).treeReduce(lambda x, y: x.union(y))\n",
    "print(letterSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b953c70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o', 'r', 'a', 'i', 'p', 'g', 'c', ' ', 'l', 'y', 'e', 'w', 'n', 'b', 'm', 't', 's'}\n"
     ]
    }
   ],
   "source": [
    "# fold\n",
    "letterSet = fruits.map(lambda fruit: set(fruit)).fold(set(), lambda x, y: x.union(y))\n",
    "print(letterSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "79de98be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reducing an empty rdd is not allowed, but fold is OK.\n",
    "r = sc.parallelize([])\n",
    "#r.reduce(lambda x, y: x+y)\n",
    "r.fold(0, lambda x, y: x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "918c8dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'o', 'r', 'a', 'i', 'p', 'g', 'c', ' ', 'l', 'y', 'e', 'w', 'n', 'b', 'm', 't', 's'}\n"
     ]
    }
   ],
   "source": [
    "# aggregate /  treeAggregate can return a different result type than the type of the RDD\n",
    "\n",
    "def f(x, y):\n",
    "    x.add(y)\n",
    "    return x\n",
    "\n",
    "letterSet = fruits.flatMap(lambda fruit: list(fruit)).aggregate(set(), f, lambda x, y: x.union(y))\n",
    "print(letterSet)\n",
    "\n",
    "# It avoids object allocation.\n",
    "# This is the most efficient way for solving this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2941d360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I have a apple\n",
      "I have a banana\n",
      "I have a canary melon\n",
      "I have a grap\n",
      "I have a lemon\n",
      "I have a orange\n",
      "I have a pineapple\n",
      "I have a strawberry\n"
     ]
    }
   ],
   "source": [
    "# foreach is an action, map is a transformation.\n",
    "fruits.foreach(lambda x: print('I have a', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c4e193",
   "metadata": {},
   "source": [
    "### Closure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fbb2c975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10))\n",
    "accum = sc.accumulator(0)\n",
    "\n",
    "def g(x):\n",
    "    global accum\n",
    "    accum += x\n",
    "\n",
    "a = rdd.foreach(g)\n",
    "\n",
    "print(accum.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fdb3e685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "44\n",
      "45\n",
      "44\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "rdd = sc.parallelize(range(10))\n",
    "accum = sc.accumulator(-1)\n",
    "\n",
    "def g(x):\n",
    "    global accum\n",
    "    accum += x\n",
    "    return x * x\n",
    "\n",
    "a = rdd.map(g)\n",
    "print(accum.value)\n",
    "# print(a.reduce(lambda x, y: x+y))\n",
    "a.cache()\n",
    "tmp = a.count()\n",
    "print(accum.value)\n",
    "print(rdd.reduce(lambda x, y: x+y))\n",
    "\n",
    "tmp = a.count()\n",
    "print(accum.value)\n",
    "print(rdd.reduce(lambda x, y: x+y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0322e7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 444:===================================================>  (96 + 4) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999999950000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 444:====================================================> (97 + 3) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "rdd = sc.parallelize(range(1000000*n) , n)\n",
    "accum = sc.accumulator(0)\n",
    "\n",
    "def g(x):\n",
    "    global accum\n",
    "    accum += x\n",
    "    return x\n",
    "\n",
    "a = rdd.map(g)\n",
    "tmp = a.count()\n",
    "print(accum.value)\n",
    "\n",
    "# correct answer: 4999999950000000\n",
    "# Spark will only update the accumulator from the successful task,and the failed tasks are completely ignored.\n",
    "# So the accumulator is computed correctly even if some tasks fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5a979cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 446:=========================================>            (78 + 6) / 101]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49999995000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 446:===============================================>      (88 + 7) / 101]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "rdd = sc.parallelize(range(100000*n) , n)\n",
    "accum = sc.accumulator(0)\n",
    "\n",
    "def g(x):\n",
    "    global accum\n",
    "    accum += x\n",
    "    return x\n",
    "\n",
    "a = rdd.map(g)\n",
    "b = a.repartition(n+1) #reduceByKey(sum)  # this causes a shuffle\n",
    "tmp = b.count()\n",
    "print(accum.value)\n",
    "\n",
    "# Because shuffle output is stored locally, if a node goes down, that shuffle output is gone. \n",
    "# Spark goes back to the stage that generated the shuffle output, looks at which tasks need\n",
    "# to be rerun, and re-executes them on one of the nodes that is still alive.\n",
    "# This results in the accumulator being an over-count\n",
    "\n",
    "# Summary: It's OK to use accumulators in an action (e.g., foreach) but not in a transformation\n",
    "# Or better: Avoid using them at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ca9ac",
   "metadata": {},
   "source": [
    "### Closure and Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0880dde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.139840\n"
     ]
    }
   ],
   "source": [
    "# From the official spark examples.\n",
    "from random import random\n",
    "from operator import add\n",
    "\n",
    "partitions = 1\n",
    "n = 100000 * partitions\n",
    "\n",
    "def f(_: int) -> int:\n",
    "    x = random() * 2 - 1\n",
    "    y = random() * 2 - 1\n",
    "    return 1 if x ** 2 + y ** 2 <= 1 else 0\n",
    "\n",
    "count = sc.parallelize(range(1, n + 1), partitions).map(f).reduce(add)\n",
    "print(\"Pi is roughly %f\" % (4.0 * count / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a36c2197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08197107068419918, 0.5106449226745052, 0.1123248153207631, 0.21871356601511205, 0.29039239441003184], [0.08197107068419918, 0.5106449226745052, 0.1123248153207631, 0.21871356601511205, 0.29039239441003184]]\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "a = sc.parallelize(range(0,10),2)\n",
    "print(a.map(lambda _: random()).glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "c5107dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08197107068419918"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ec596",
   "metadata": {},
   "source": [
    "### mapPartitions and mapPartitionsWithIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f3e68614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elppa', 'ananab', 'nolem yranac', 'parg', 'nomel', 'egnaro', 'elppaenip', 'yrrebwarts']\n"
     ]
    }
   ],
   "source": [
    "# mapPartitions\n",
    "\n",
    "def f(pa):\n",
    "    l = []\n",
    "    for x in pa:\n",
    "        l.append(x[::-1])\n",
    "    return l\n",
    "        \n",
    "fruitsReversed = fruits.mapPartitions(f)\n",
    "print(fruitsReversed.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "22669a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elppa', 'ananab', 'nolem yranac', 'parg', 'nomel', 'egnaro', 'elppaenip', 'yrrebwarts']\n"
     ]
    }
   ],
   "source": [
    "# It's more efficient to use yield\n",
    "\n",
    "def f(pa):\n",
    "    for x in pa:\n",
    "        yield x[::-1]\n",
    "\n",
    "fruitsReversed = fruits.mapPartitions(f)\n",
    "print(fruitsReversed.collect())\n",
    "\n",
    "#  It provides a facility to do heavy initializations (for example Database connection) once for each partition\n",
    "# instead of doing it on every element in the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f9afd4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['apple', 'banana', 'canary melon', 'grap', 'lemon'], ['orange', 'pineapple', 'strawberry']]\n",
      "[['apple', 'banana', 'canary melon', 'grap', 'lemon'], ['orange', 'pineapple', 'strawberry']]\n"
     ]
    }
   ],
   "source": [
    "# Can also do some transformation on the partition level\n",
    "\n",
    "def f(pa):\n",
    "    return sorted(pa, reverse = False)\n",
    "\n",
    "print(fruits.glom().collect())\n",
    "print(fruits.mapPartitions(f).glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6b285483",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0apple', '0banana', '0canary melon', '0grap', '0lemon'], ['1orange', '1pineapple', '1strawberry']]\n"
     ]
    }
   ],
   "source": [
    "# mapPartitionsWithIndex\n",
    "\n",
    "def f(i, pa):\n",
    "    for x in pa:\n",
    "        yield str(i) + x\n",
    "\n",
    "fruitsReversed = fruits.mapPartitionsWithIndex(f)\n",
    "print(fruitsReversed.glom().collect())\n",
    "\n",
    "# These two functions will be useful for advanced algorithm design (will see later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fb55bb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4915180891510291, 0.6501074950025437, 0.7425690415610158, 0.8094631097993955, 0.30904201290698985], [0.7167792617493542, 0.3987359268395958, 0.027887404178219444, 0.9969306184063441, 0.2764869188716471]]\n"
     ]
    }
   ],
   "source": [
    "# Check that random numbers are different\n",
    "from random import random, seed\n",
    "from time import time\n",
    "\n",
    "s = time()\n",
    "\n",
    "def f(index, it):\n",
    "    seed(index + s)\n",
    "    for i in it:\n",
    "        yield random()\n",
    "\n",
    "print(sc.parallelize(range(10), 2).mapPartitionsWithIndex(f).glom().collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "58fb4bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 455:====================================>                 (67 + 6) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi is roughly 3.141356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 455:============================================>         (83 + 6) / 100]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Correct version for computing Pi\n",
    "from random import random, seed\n",
    "from time import time\n",
    "\n",
    "partitions = 100\n",
    "n = 100000 * partitions\n",
    "\n",
    "s = time()\n",
    "\n",
    "def f(index, it):\n",
    "    seed(index + s)\n",
    "    for i in it:\n",
    "        x = random() * 2 - 1\n",
    "        y = random() * 2 - 1\n",
    "        yield 1 if x ** 2 + y ** 2 <= 1 else 0\n",
    "\n",
    "count = sc.parallelize(range(1, n + 1), partitions).mapPartitionsWithIndex(f).sum()\n",
    "\n",
    "print(\"Pi is roughly\", 4.0 * count / n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beeff3f",
   "metadata": {},
   "source": [
    "### Linear-time selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "661ff639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43]\n"
     ]
    }
   ],
   "source": [
    "# An inefficient algorithm: requires a shuffle + a scan\n",
    "data = [34, 67, 21, 56, 47, 89, 12, 44, 74, 43, 26]\n",
    "A = sc.parallelize(data,2)\n",
    "k = 4\n",
    "\n",
    "print(A.sortBy(lambda x: x).zipWithIndex().map(lambda x: (x[1],x[0])).lookup(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "18e47468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "data = [34, 67, 21, 56, 47, 89, 12, 44, 74, 43, 26]\n",
    "A = sc.parallelize(data,2)\n",
    "k = 4\n",
    "\n",
    "while True:\n",
    "    x = A.first()\n",
    "    A1 = A.filter(lambda z: z < x)\n",
    "    A2 = A.filter(lambda z: z > x)\n",
    "    mid = A1.count()\n",
    "    if mid == k:\n",
    "        print(x)\n",
    "        break\n",
    "    if k < mid:\n",
    "        A = A1\n",
    "    else:\n",
    "        A = A2\n",
    "        k = k - mid - 1\n",
    "    A.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67375e6c",
   "metadata": {},
   "source": [
    "### Key-Value Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "86d4f5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, <pyspark.resultiterable.ResultIterable object at 0x7f96dc477220>), (12, <pyspark.resultiterable.ResultIterable object at 0x7f96dc477160>), (4, <pyspark.resultiterable.ResultIterable object at 0x7f96dc477070>), (10, <pyspark.resultiterable.ResultIterable object at 0x7f96dc477130>), (5, <pyspark.resultiterable.ResultIterable object at 0x7f96dc477af0>), (9, <pyspark.resultiterable.ResultIterable object at 0x7f96dc477b20>)]\n",
      "banana\n",
      "orange\n"
     ]
    }
   ],
   "source": [
    "# groupByKey\n",
    "groupFruitsByLength = fruits.map(lambda fruit: (len(fruit), fruit)).groupByKey()\n",
    "print(groupFruitsByLength.take(10))\n",
    "for x in groupFruitsByLength.take(1)[0][1]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "61793607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(6, 2), (12, 1), (4, 1), (10, 1), (5, 2), (9, 1)]\n"
     ]
    }
   ],
   "source": [
    "# reduceByKey: this more efficient\n",
    "# reduceByKey will compute local sums for each key in each partition and combine those local sums \n",
    "# into larger sums after shuffling.\n",
    "\n",
    "numFruitsByLength = fruits.map(lambda fruit: (len(fruit), 1)).reduceByKey(lambda x, y: x + y)\n",
    "print(numFruitsByLength.take(10))\n",
    "\n",
    "# aggregateByKey, foldByKey also available.\n",
    "# but there is no treeAggregateByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a166e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Course', 2), ('Information', 1), ('systems,', 1), ('cloud', 1), ('parallel', 1), ('as', 1), ('in', 2), ('mining', 1), ('massive', 1), ('amount', 1), ('of', 3), ('even', 1), ('servers', 1), ('centers.', 1), ('both', 1), ('hands-on', 1), ('this', 1), ('new', 1), ('Lecture', 1), ('videos', 1)]\n"
     ]
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "lines = sc.textFile('data/course.txt')\n",
    "counts = lines.flatMap(lambda x: x.split()) \\\n",
    "              .map(lambda x: (x, 1)) \\\n",
    "              .reduceByKey(lambda x,y:x+y)\n",
    "print(counts.take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ed4ba3fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Big', 1), ('Course', 2), ('Description', 1), ('Information', 1), ('Lecture', 1), ('This', 1), ('across', 1), ('amount', 1), ('and', 3), ('as', 1), ('both', 1), ('centers.', 1), ('cloud', 1), ('commodity', 1), ('computing', 1), ('course', 1), ('data', 4), ('emerge', 1), ('enabling', 1), ('even', 1)]\n",
      "[('data', 4), ('of', 3), ('and', 3), ('Course', 2), ('in', 2), ('the', 2), ('Information', 1), ('systems,', 1), ('cloud', 1), ('parallel', 1), ('as', 1), ('mining', 1), ('massive', 1), ('amount', 1), ('even', 1), ('servers', 1), ('centers.', 1), ('both', 1), ('hands-on', 1), ('this', 1)]\n",
      "{'Course': 2, 'Information': 1, 'systems,': 1, 'cloud': 1, 'parallel': 1, 'as': 1, 'in': 2, 'mining': 1, 'massive': 1, 'amount': 1, 'of': 3, 'even': 1, 'servers': 1, 'centers.': 1, 'both': 1, 'hands-on': 1, 'this': 1, 'new': 1, 'Lecture': 1, 'videos': 1, 'Description': 1, 'Big': 1, 'data': 4, 'including': 1, 'computing': 1, 'and': 3, 'processing': 1, 'frameworks,': 1, 'emerge': 1, 'enabling': 1, 'technologies': 1, 'managing': 1, 'the': 2, 'across': 1, 'hundreds': 1, 'or': 1, 'thousands': 1, 'commodity': 1, 'This': 1, 'course': 1, 'exposes': 1, 'students': 1, 'to': 1, 'theory': 1, 'experience': 1, 'technology.': 1}\n"
     ]
    }
   ],
   "source": [
    "print(counts.sortByKey().take(20))\n",
    "print(counts.sortBy(lambda x: x[1], False).take(20))\n",
    "print(counts.collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "93d1507b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.lookup('data')\n",
    "# This scans the whole RDD, unless there is a partitioner (to be discussed later)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd9597",
   "metadata": {},
   "source": [
    "### Join vs. Broadcast Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a668a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, ('Apple', (134, 'OK'))), (1, ('Apple', (135, 'OK'))), (1, ('Apple', (45, 'OK'))), (1, ('apple', (134, 'OK'))), (1, ('apple', (135, 'OK'))), (1, ('apple', (45, 'OK'))), (2, ('Orange', (53, 'OK'))), (3, ('TV', (34, 'OK'))), (5, ('Computer', (162, 'Error')))]\n"
     ]
    }
   ],
   "source": [
    "# Join simple example\n",
    "\n",
    "products = sc.parallelize([(1, \"Apple\"), (1, 'apple'), (2, \"Orange\"), (3, \"TV\"), (5, \"Computer\")])\n",
    "#trans = sc.parallelize([(1, 134, \"OK\"), (3, 34, \"OK\"), (5, 162, \"Error\"), (1, 135, \"OK\"), (2, 53, \"OK\"), (1, 45, \"OK\")])\n",
    "trans = sc.parallelize([(1, (134, \"OK\")), (3, (34, \"OK\")), (5, (162, \"Error\")), (1, (135, \"OK\")), (2, (53, \"OK\")), (1, (45, \"OK\"))])\n",
    "\n",
    "print(products.join(trans).take(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6084f534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Apple', (134, 'OK')), (3, 'TV', (34, 'OK')), (5, 'Computer', (162, 'Error')), (1, 'Apple', (135, 'OK')), (2, 'Orange', (53, 'OK')), (1, 'Apple', (45, 'OK'))]\n"
     ]
    }
   ],
   "source": [
    "products = {1: \"Apple\", 2: \"Orange\", 3: \"TV\", 4: \"PC\", 5: \"Computer\"}\n",
    "trans = sc.parallelize([(1, (134, \"OK\")), (3, (34, \"OK\")), (5, (162, \"Error\")), (1, (135, \"OK\")), (2, (53, \"OK\")), (1, (45, \"OK\"))])\n",
    "\n",
    "broadcasted_products = sc.broadcast(products)\n",
    "\n",
    "results = trans.map(lambda x: (x[0], broadcasted_products.value[x[0]], x[1]))\n",
    "#  results = trans.map(lambda x: (x[0], products[x[0]], x[1]))\n",
    "print(results.take(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f33a4869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (['Apple', 'apple'], [(134, 'OK'), (135, 'OK'), (45, 'OK')])\n",
      "2 (['Orange'], [(53, 'OK')])\n",
      "3 (['TV'], [(34, 'OK')])\n",
      "4 (['PC'], [])\n",
      "5 (['Computer'], [(162, 'Error')])\n"
     ]
    }
   ],
   "source": [
    "# Compare with cogroup\n",
    "\n",
    "products = sc.parallelize([(1, \"Apple\"), (1, 'apple'),  (2, \"Orange\"), (3, \"TV\"), (4, \"PC\"), (5, \"Computer\")])\n",
    "trans = sc.parallelize([(1, (134, \"OK\")), (3, (34, \"OK\")), (5, (162, \"Error\")), (1, (135, \"OK\")), (2, (53, \"OK\")), (1, (45, \"OK\"))])\n",
    "\n",
    "for x,y in products.cogroup(trans).collect():\n",
    "    print(x, tuple(map(list, y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
